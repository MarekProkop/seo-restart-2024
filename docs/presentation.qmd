---
title: "SEO + R + OpenIA API = ❤️"
author: "Marek Prokop & ChatGPT"
institute: PROKOP software s.r.o.
date: today
date-format: "D. M. YYYY"
format:
  revealjs:
    theme: [white, custom.scss]
    highlight-style: a11y
    code-line-numbers: false
    auto-stretch: true
    df-print: paged
    controls: true
    controls-layout: bottom-right
    progress: true
    self-contained: false
  beamer:
    aspectratio: 169
---

## Začnu praktickým příkladem

1. Načtu dotazy ze Search Console.
1. Rozdělím je do několika tematických segmentů.
1. Vyrobím report s několika grafy a slovním shrnutím.


```{r}
#| label: libs
#| include: false

library(tidyverse)
library(searchConsoleR)
library(openai)
library(rvest)
library(xml2)
library(chromote)
library(here)
library(gt)
library(epoxy)

epoxy_transform_set(
  .comma = scales::label_number(big.mark = " "),
  .percent = scales::label_percent(accuracy = 0.01),
  .double = scales::label_number(big.mark = " ", accuracy = 0.01),
  .date = function(x) {
    x |>
      format("%d. %m. %Y") |>
      str_remove_all("\\b0")
  },
  .datetime = function(x) {
    x |>
      format("%d. %m. %Y %H:%M") |>
      str_remove_all("\\b0")
  }
)

scr_auth(email = Sys.getenv("MY_GOOGLE_ACCOUNT"))

source(here::here("R", "get_embeddings.R"))
source(here::here("R", "segment_queries.R"))
source(here::here("R", "get_content.R"))

```

```{r}
#| label: parameters

site <- "http://www.marekp.cz/"
date_from <- today() - 92
date_to <- today() - 3

segments <- tribble(
  ~name,       ~description,
  "harmonika", "harmonica, blues harp, music",
  "turistika", "turistika, trasa, cesta, pěší výlet, dálkový pochod",
  "OSM",       "OpenStreetMap, OSM", 
  "koťata",    "kotě, koťata, koťátko"
)

other_name <- "ostatní"

threshold <- 0.3

cache_file_name <- here("data", "embeddings.rds")

```

## Načtu dotazy ze Search Console

```{r}
#| echo: true
#| message: false

queries <- search_analytics(
  siteURL = "http://www.marekp.cz/",
  dimensions = "query"
)
queries
```

## Dotazy rozdělím do segmentů

```{r}
#| label: segment queries
#| rows.print: 15

segmented_queries <- segment_queries(
  queries = queries |> 
    mutate(
      embedding = get_embeddings(
        texts = query,
        cache_path = cache_file_name,
        model = "text-embedding-3-small"
      )
    ),
  segments = segments |>
    mutate(
      embedding = get_embeddings(
        texts = description,
        cache_path = cache_file_name,
        model = "text-embedding-3-small"
      )
    ),
  threshold = threshold,
  other_name = other_name
)

segmented_queries |> 
  arrange(desc(impressions)) |> 
  select(query, segment)
```

## Segmenty zobrazím s příklady dotazů

```{r}
#| label: sample queries

set.seed(123)

segmented_queries |> 
  group_by(segment) |> 
  slice_sample(n = 20) |> 
  summarise(
    queries = paste(query, collapse = ", ")
  ) |> 
  ungroup() |> 
  gt()
```


## Segmenty mohu i agregovat

```{r}
#| label: aggregated segments

aggregated_segments <- segmented_queries |>
  group_by(segment) |> 
  summarise(
    queries = n(),
    position = weighted.mean(position, impressions),
    impressions = sum(impressions),
    clicks = sum(clicks),
    ctr = clicks / impressions,
    impressions_per_query = impressions / queries,
    clicks_per_query = clicks / queries
  ) |> 
  ungroup() |> 
  relocate(position, .after = ctr) |> 
  arrange(segment)

aggregated_segments |> 
  gt() |> 
  tab_header(
    title = "Metriky Search Console agregované podle segmentů dotazů"
  ) |> 
  fmt_integer(queries:clicks, sep_mark = " ") |> 
  fmt_percent(ctr, sep_mark = " ", dec_mark = ",") |> 
  fmt_number(
    c(position, impressions_per_query, clicks_per_query), sep_mark = " ", dec_mark = ","
  )
```

## Nebo z nich vykreslit různé grafy

```{r}
#| label: charts

aggregated_segments |> 
  pivot_longer(
    cols = queries:position,
    names_to = "metric"
  ) |> 
  mutate(
    metric = as_factor(metric),
    segment = fct_rev(segment)
  ) |> 
  ggplot(aes(x = segment, y = value)) +
  geom_col() +
  coord_flip() +
  facet_wrap(vars(metric), scales = "free_x") +
  labs(
    title = "Metriky Search Console agregované podle segmentů dotazů",
    y = NULL
  )
  
```

## Vývoj v čase

```{r}
#| label: time series
#| message: false

search_analytics(
  siteURL = site,
  startDate = date_from,
  endDate = date_to,
  dimensions = c("date", "query")
) |>
  left_join(
    segmented_queries |> 
      select(query, segment),
    by = join_by(query)
  ) |> 
  group_by(date, segment) |> 
  summarise(
    impressions = sum(impressions)
  ) |> 
  ggplot(aes(x = date, y = impressions, fill = segment)) +
  geom_area() +
  scale_fill_brewer(type = "qual", palette = 6) +
  labs(
    title = "Vývoj impresí segmentů dotazů v čase"
  )

```

## Z toho všeho můžu udělat report pro klienta

```{=html}
<iframe width="960" height="500" src="https://marekprokop.github.io/seo-restart-2024/query-segments.html"></iframe>
```

# Jak to funguje

## Text embeddings

- Každé slovo, věta či delší text jde reprezentovat vektorem v n-rozměrném prostoru.
- Tento vektor se nazývá word (nebo text) embedding.
- Vektory více textů jsou v n-rozměrném prostoru umístěny na různých místech a svírají různé úhly.
- Vektory, které jsou na podobných místech a míří hodně podobným směrem, pravděpodobně reprezentují významově hodně podobné texty.
- Podobnost vektorů jde spočítat klasickou geometrií. Já používám cosinovou podobnost.

## Text embeddings v OpenAI API

- Open AIP API nabízí 3 modely pro text embeddings. Já používám *text-embedding-3-small*.
- Model *text-embedding-3-small* dokáže podle dokumentace OpenAI vygeberovat za 1 USD text embeddings pro 62 500 stránek o 800 tokenech. Za přípravu této přednášky jsem utratil $0.02 :-)
- Více se dočtete v [dokumentaci k text embeddings OpenAI API](https://platform.openai.com/docs/guides/embeddings/embeddings).

## *marek prokop* jako vektor :-)

```{r}
#| label: vector marek prokop

get_embeddings("marek prokop", cache_file_name) |> 
  pluck(1)
```


# Jak to můžete sami používat

## Předpoklady

- Musíte mít přístup k [Search Consoli](https://search.google.com/search-console) alespoň jednoho webu. 
- Dále musíte mít přístup k [OpenAI API](https://platform.openai.com/) a [vygenerovaný API klíč](https://platform.openai.com/account/api-keys).
- V proměnné prostředí `MY_GOOGLE_ACCOUNT` máte uloženou e-mailovou adresu svého Google účtu.
- V proměnné prostředí `OPENAI_API_KEY` máte klíč k API OpenAI.

## Příprava

Zmíněné proměnné vytvoříte např. takto:

1.  Nainstalujte si balíček *usethis*.

2.  Z konsole zadejte příkaz `usethis::edit_r_environ()`. Tím se vám v editoru otevře soubor *.Renviron*.

3.  Do souboru *.Renviron* přidejte tyto dva řádky s upravenými hodnotami:

    ```         
    MY_GOOGLE_ACCOUNT = "vas.email@gmail.com"
    OPENAI_API_KEY = "váš_api_key"
    ```

4.  Soubor uložte a restartujte R (v RStudiu příkazem *Restart R* z menu *Session*).


## Naklonujete si repositář

[https://github.com/MarekProkop/seo-restart-2024](https://github.com/MarekProkop/seo-restart-2024)

## Upravíte <br />`docs/query-segments.qmd`

- V hlavičce změníte titulek, podtitulek a autora
- V bloku s labelem *parameters* změníte:
  - property SearCh Console
  - názvy a popisy požadovaných segmentů
  - název skupiny pro ostatní
  - práh zařazení do ostatní

## Vyrenderujete report

V RStudiu tlačítkem *Render*.

# K čemu dalšímu se embeddings z OpenAI API hodí

## Optimalizace textu stránky

1. Stáhnu si text stránky balíčkem *rvest*, případně kombinací *chromote* + *rvest*.
1. Z textu získám ebeddings.
1. Získám ebeddings dotazu, na který chci rankovat.
1. Spočítám cosinovou podobnost.
1. Upravím text stránky, abych dosáhl větší podobnosti.

## Harmonica layout chart - výsledky

```{r}
#| label: harmonica results
#| echo: true

queries |> 
  filter(
    str_detect(query, "layout")
  ) |> 
  gt()
```

## Harmonica layout chart - text stránky

```{r}
#| label: harmonica copy
#| echo: true
#| output-location: slide

page_content_cache <- "../data/page-content.rds"

if (file.exists(page_content_cache)) {
  page_content <- read_rds(page_content_cache)
} else {
  rendered_html <- "http://marekp.cz/harmonica/" |> 
    get_rendered_html() |> 
    read_html()
  page_content <- rendered_html |> 
    html_element("title") |> 
    html_text2() |> 
    paste(
      rendered_html |> get_content(),
      sep = "\n"
    )
  write_rds(page_content, page_content_cache)
}

cat(page_content)
```

## Harmonica layout chart - text embeddings

```{r}
#| label: harmonica text embeddings
#| echo: true

cosine_similarity(
  get_embeddings(page_content, cache_path = cache_file_name) |> pluck(1),
  get_embeddings("harmonica layout", cache_path = cache_file_name) |> pluck(1)
)

```

## Harmonica layout chart - víc dotazů

```{r}
#| label: harmonica text multiple queries
#| echo: true

tibble(query = c(
  "harmonica layout", "harmonica pentatonic scale", 
  "harmonica tuning chart", "harmonica chords", "slon v porcelánu"
)) |> 
  mutate(
    embedding = get_embeddings(query, cache_path = cache_file_name),
    similarity = map_dbl(
      embedding, cosine_similarity, 
      get_embeddings(page_content, cache_path = cache_file_name) |> pluck(1)
    )
  ) |> 
  select(!embedding)
```


# A to je pro dnešek všechno

## Kam dál

- [Od Excelu k R](https://www.prokopsw.cz/bookdown/excel-r/) -- pokud chcete s R začít.
- [Děláte digitální marketing a chcete začít používat R? Tohle je váš studijní plán](https://marekprokop.github.io/jak-pracuju/posts/r-pro-digitalni-marketing/) -- článek pro digitální marketéry, kteří to s R myslí vážně.
- [Alternativní metoda klasifikace dotazů](https://github.com/MarekProkop/seologer-2023), kterou jsem popisoval na SEO Loggeru 2023.
- [Dokumentace k OpenAI API](https://platform.openai.com/docs/overview)

# Děkuju za pozornost

Dotazy pište na: mprokop@prokopsw.cz
